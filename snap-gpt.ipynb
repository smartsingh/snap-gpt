{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0e6acea-f721-46da-84d3-14beefe38a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 616, which is longer than the specified 600\n",
      "Created a chunk of size 716, which is longer than the specified 600\n",
      "Created a chunk of size 677, which is longer than the specified 600\n",
      "Created a chunk of size 637, which is longer than the specified 600\n",
      "Created a chunk of size 634, which is longer than the specified 600\n",
      "Created a chunk of size 612, which is longer than the specified 600\n",
      "Created a chunk of size 627, which is longer than the specified 600\n",
      "Created a chunk of size 720, which is longer than the specified 600\n",
      "Created a chunk of size 843, which is longer than the specified 600\n",
      "Created a chunk of size 999, which is longer than the specified 600\n",
      "Created a chunk of size 803, which is longer than the specified 600\n",
      "Created a chunk of size 679, which is longer than the specified 600\n",
      "Created a chunk of size 816, which is longer than the specified 600\n",
      "Created a chunk of size 616, which is longer than the specified 600\n",
      "Created a chunk of size 685, which is longer than the specified 600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "#import data using langchain and feed it into a vectorstore for use by gpt3.5\n",
    "from langchain.text_splitter import CharacterTextSplitter as CTS\n",
    "from langchain.document_loaders import DirectoryLoader as DL\n",
    "from langchain.document_loaders import CSVLoader as CSVL\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import pickle\n",
    "import config\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = config.gptkey\n",
    "\n",
    "def data_train():\n",
    "    loader = DL(\"data/\")\n",
    "    raw_docs = loader.load()\n",
    "\n",
    "    text_splitter = CTS(\n",
    "        separator = \"\\n\\n\",\n",
    "        chunk_size = 600,\n",
    "        chunk_overlap = 100,\n",
    "        length_function = len,\n",
    "    )\n",
    "    \n",
    "    docs = text_splitter.split_documents(raw_docs)\n",
    "    \n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "    \n",
    "    #workaround to pickling the vectorstore\n",
    "    vectorstore.save_local(\"vectorstore\")\n",
    "\n",
    "    return print(\"done!\")\n",
    "\n",
    "data_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "074f8241-20bb-497a-9889-f4cd7d00b693",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.vectorstores.base import VectorStoreRetriever\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "#defining base prompt\n",
    "template = \"\"\"You are an expert at Collectible Card Games, like Magic: The Gathering. You have studied the rules and cards for another\n",
    "collectible card game called Marvel SNAP, which is entirely digital and is based on popular characters and settings made by Marvel Comics.\n",
    "Your role is to coach Marvel SNAP players on how to improve their gameplay and recommend possible 12-card deck combinations.\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\"\"\"\n",
    "\n",
    "base_prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "#building loaders/chatbot\n",
    "def load_retriever():\n",
    "    x = FAISS.load_local(\"vectorstore\", OpenAIEmbeddings())\n",
    "    retriever = VectorStoreRetriever(vectorstore=x)\n",
    "\n",
    "    return retriever\n",
    "\n",
    "def get_basic_qa_chain():\n",
    "    llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0)\n",
    "    retriever = load_retriever()\n",
    "    memory = ConversationBufferMemory(\n",
    "        memory_key=\"chat_history\", return_messages=True)\n",
    "    model = ConversationalRetrievalChain.from_llm(\n",
    "        llm=llm,\n",
    "        retriever=retriever,\n",
    "        memory=memory)\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
